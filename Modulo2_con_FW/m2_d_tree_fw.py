# -*- coding: utf-8 -*-
"""M2_d_tree_FW.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X1Hpuv5llX6TzEou8VtCqsp47ZTtvoy-

# Momento de Retroalimentación: Módulo 2 Uso de framework o biblioteca de aprendizaje máquina para la implementación de una solución. (Portafolio Implementación)

### Importar librerias
Se importan las bibliotecas necesarias como numpy, pandas y algunas funciones específicas de scikit-learn.
"""

# Importación de las bibliotecas necesarias
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix, classification_report

"""### Leer los datos

Pide al usuario la ubicación del archivo CSV a cargar y luego lo lee utilizando la biblioteca pandas.
"""

# Carga del dataset
filename = input('''Ingresa la ruta donde se encuentra el archivo + /filename.csv
                 => ''')
df = pd.read_csv(filename, skiprows=1, header=None)

print("Muestra del dataset original:")
print(df.head())

# Extracción de características y etiquetas
X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values

# División del dataset en conjuntos de entrenamiento y temporal (test + validación)
X_train_temp, X_temp, y_train_temp, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)

# División del conjunto temporal en conjuntos de prueba y validación
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Visualizar la separación de los datos
print("\nDatos de entrenamiento (primeras 5 filas):")
print(X_train_temp[:5])
print(y_train_temp[:5])
print("\nDatos de validación (primeras 5 filas):")
print(X_val[:5])
print(y_val[:5])
print("\nDatos de prueba (primeras 5 filas):")
print(X_test[:5])
print(y_test[:5])

# Lista para almacenar métricas
train_errors, val_errors, train_bias, test_bias = [], [], [], []

# Entrenar el árbol incrementando su profundidad para ver cómo aprende
for depth in range(1, 11):
    clf = DecisionTreeClassifier(max_depth=depth)
    clf.fit(X_train_temp, y_train_temp)

    # Realiza predicciones y calcula la precisión
    y_train_pred = clf.predict(X_train_temp)
    y_test_pred = clf.predict(X_test)
    train_accuracy = accuracy_score(y_train_temp, y_train_pred)
    test_accuracy = accuracy_score(y_test, y_test_pred)

    # Almacenar sesgo y error
    train_errors.append(train_accuracy)
    val_errors.append(test_accuracy)
    train_bias.append(1 - train_accuracy)
    test_bias.append(1 - test_accuracy)

"""### Visualización
Muestra una gráfica de precisión (accuracy) en función de la profundidad del árbol para visualizar cómo va aprendiendo el modelo.
"""

# Listas para almacenar métricas
train_errors, val_errors = [], []

# Evaluar la precisión a medida que aumenta el tamaño del conjunto de entrenamiento
for m in range(1, len(X_train)):
    clf = DecisionTreeClassifier(max_depth=10)
    clf.fit(X_train[:m], y_train[:m])

    y_train_predict = clf.predict(X_train[:m])
    y_val_predict = clf.predict(X_test)

    train_errors.append(accuracy_score(y_train[:m], y_train_predict))
    val_errors.append(accuracy_score(y_test, y_val_predict))

# Gráficar la curva de aprendizaje
plt.plot(np.sqrt(train_errors), "r-+", linewidth=2, label="train")
plt.plot(np.sqrt(val_errors), "b-", linewidth=3, label="val")
plt.title('Curva de Aprendizaje')
plt.xlabel('Tamaño del conjunto de entrenamiento')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

"""### Grado de bias

Se ha calculado el bias como la diferencia entre el accuracy ideal (1.0) y el accuracy promedio del conjunto de validación.
"""

# Gráficas de sesgo y precisión en función de la profundidad del árbol
fig, ax = plt.subplots(2, 1, figsize=(10, 12))

# Sesgo para el conjunto de entrenamiento
ax[0].plot(range(1, len(train_bias) + 1), train_bias, label="Sesgo (1 - Train Accuracy)", color="blue")
ax[0].set_title("Sesgo en función de la profundidad del árbol (Conjunto de Entrenamiento)")
ax[0].set_xlabel("Profundidad del Árbol")
ax[0].set_ylabel("Sesgo")
ax[0].legend()

# Sesgo para el conjunto de prueba
ax[1].plot(range(1, len(test_bias) + 1), test_bias, label="Sesgo (1 - Test Accuracy)", color="red")
ax[1].set_title("Sesgo en función de la profundidad del árbol (Conjunto de Prueba)")
ax[1].set_xlabel("Profundidad del Árbol")
ax[1].set_ylabel("Sesgo")
ax[1].legend()

plt.tight_layout()
plt.show()

"""#### Grado de varianza

 Se calcula directamente como la varianza del accuracy en el conjunto de validación.
"""

# Cálculo del bias y varianza
bias = 1 - np.mean(val_errors)
variance = np.var(val_errors)

def categorizar_medida(medida):
    if medida < 0.1:
        return "Bajo"
    elif medida < 0.3:
        return "Medio"
    else:
        return "Alto"

bias_categoria = categorizar_medida(bias)
varianza_categoria = categorizar_medida(variance)

print(f"Grado de Bias (Sesgo): {bias:.4f} - {bias_categoria}")
print(f"Grado de Varianza: {variance:.4f} - {varianza_categoria}")

"""### Gráfica del error para observar validación de la varianza"""

# Gráfica de error de entrenamiento y validación en función de la profundidad del árbol
plt.figure(figsize=(10, 6))

# Error de entrenamiento y validación
plt.plot(range(1, len(train_errors) + 1), [1 - acc for acc in train_errors], label="Error de Entrenamiento", color="blue")
plt.plot(range(1, len(val_errors) + 1), [1 - acc for acc in val_errors], label="Error de Validación", color="red")

# Configuración de la gráfica
plt.title("Error en función de la profundidad del árbol")
plt.xlabel("Profundidad del Árbol")
plt.ylabel("Error")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""### Nivel de ajuste del modelo

Se determina por las características generales de bias y varianza.

1. Si ambos son altos, el modelo está underfitting y overfitting al mismo tiempo.
2. Si solo el bias es alto, es underfitting.
3. Si solo la varianza es alta, es overfitting.
4. Si ambos son bajos, el modelo está equilibrado.
"""

if bias_categoria == "Alto" and varianza_categoria == "Alto":
    print("El modelo presenta alto bias y alta varianza (underfitting y overfitting)")
elif bias_categoria == "Alto":
    print("El modelo presenta alto bias (underfitting)")
elif varianza_categoria == "Alto":
    print("El modelo presenta alta varianza (overfitting)")
else:
    print("El modelo tiene un buen equilibrio entre bias y varianza (fitt)")

"""### Gráficas de SESGO, VARIANZA Y NIVEL DE AJUSTE"""

# Gráficar Sesgo, Varianza y Nivel de Ajuste en subplots
fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(8, 12))

# Sesgo (Bias)
bias_array = [1 - acc for acc in train_errors]
ax[0].plot(range(1, len(train_errors) + 1), bias_array, label="Sesgo (1 - Train Accuracy)", color="blue")
ax[0].set_title("Sesgo en función del tamaño del conjunto de entrenamiento")
ax[0].set_xlabel("Tamaño del conjunto de entrenamiento")
ax[0].set_ylabel("Sesgo")
ax[0].legend()

# Varianza
variance_array = [val_errors[i] - train_errors[i] for i in range(len(val_errors))]
ax[1].plot(range(1, len(val_errors) + 1), variance_array, label="Varianza", color="red")
ax[1].set_title("Varianza en función del tamaño del conjunto de entrenamiento")
ax[1].set_xlabel("Tamaño del conjunto de entrenamiento")
ax[1].set_ylabel("Varianza")
ax[1].legend()

# Nivel de Ajuste (Overfitting/Underfitting)
ax[2].plot(range(1, len(train_errors) + 1), train_errors, label="Train Accuracy", color="blue")
ax[2].plot(range(1, len(val_errors) + 1), val_errors, label="Validation Accuracy", color="red")
ax[2].set_title("Nivel de Ajuste en función del tamaño del conjunto de entrenamiento")
ax[2].set_xlabel("Tamaño del conjunto de entrenamiento")
ax[2].set_ylabel("Accuracy")
ax[2].legend()

plt.tight_layout()
plt.show()

"""### MEJORAS DEL MODELO"""

# a. Ajuste de la profundidad máxima del árbol
depths = list(range(1, 11))
accuracies_depths = []

for depth in depths:
    clf = DecisionTreeClassifier(max_depth=depth)
    clf.fit(X_train, y_train)
    accuracies_depths.append(clf.score(X_val, y_val))

plt.plot(depths, accuracies_depths, label="Accuracy según Profundidad")
plt.xlabel('Profundidad del Árbol')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# b. Uso de regularización (min_samples_leaf)
samples_leaf = list(range(1, 20, 2))
accuracies_samples = []

for sample in samples_leaf:
    clf = DecisionTreeClassifier(min_samples_leaf=sample)
    clf.fit(X_train, y_train)
    accuracies_samples.append(clf.score(X_val, y_val))

plt.plot(samples_leaf, accuracies_samples, label="Accuracy según min_samples_leaf")
plt.xlabel('Min_samples_leaf')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# c. Uso de característica de importancia para la selección de características
clf = DecisionTreeClassifier()
clf.fit(X_train, y_train)
importances = clf.feature_importances_
indices = np.argsort(importances)[::-1]
plt.bar(range(X_train.shape[1]), importances[indices])
plt.xlabel('Características')
plt.ylabel('Importancia')
plt.title('Importancia de Características')
plt.show()